# Product Requirements Document (PRD)

**Project Name:** Q-LABS-Hybrid-Solver
**Team Name:** I Tried
**GitHub Repository:** [https://github.com/Mamoon794/2026-NVIDIA](https://github.com/Mamoon794/2026-NVIDIA)

---

> **Note to Judges:** This PRD outlines our strategy for implementing a Quantum-Enhanced Memetic Tabu Search (QE-MTS) to solve the Low Autocorrelation Binary Sequences (LABS) problem. Our approach combines a Counteradiabatic quantum optimization routine with a GPU-accelerated classical local search.

---

## 1. Team Roles & Responsibilities

| Role | Name | GitHub Handle | Discord Handle |
| --- | --- | --- | --- |
| **Project Lead** (Architect) | Mamoon Akhtar | Mamoon794 | alphaprime7537 |
| **GPU Acceleration PIC** (Builder) | Mamoon Akhtar | Mamoon794 | alphaprime7537 |
| **Quality Assurance PIC** (Verifier) | Mamoon Akhtar | Mamoon794 | alphaprime7537 |
| **Technical Marketing PIC** (Storyteller) | Mamoon Akhtar | Mamoon794 | alphaprime7537 |

---

## 2. The Architecture

**Owner:** Project Lead

### Choice of Quantum Algorithm

* **Algorithm:** **Trotterized Counteradiabatic Optimization**
* I implement a specific Counteradiabatic (CD) drive derived for the LABS Hamiltonian ().
* The circuit utilizes specific "Pauli Gadgets" for 2-body () and 4-body () interaction terms.
* The evolution is governed by an annealing schedule  and a CD coefficient  which determines the rotation angles .


* **Motivation:**
* **Efficiency:** Standard QAOA requires deep circuits to optimize the complex LABS landscape. The Counteradiabatic approach suppresses diabatic transitions, allowing us to stay near the ground state with significantly fewer entangling gates than QAOA.
* **Hybrid Synergy:** I do not rely on the quantum computer to find the *perfect* solution. Instead, I use the CD protocol to sample a distribution of "high-quality" bitstrings to seed our classical Memetic Tabu Search, bypassing the "cold start" problem of random initialization.



### Literature Review

* **Reference:** *Scaling advantage with quantum-enhanced memetic tabu search for LABS*.
* **Relevance:** This is the foundational paper for our implementation. It provides the derivation for the first-order approximate adiabatic gauge potential and the specific Trotter decomposition I implemented in our CUDA-Q kernels.

---

## 3. The Acceleration Strategy

**Owner:** GPU Acceleration PIC

### Quantum Acceleration (CUDA-Q)

* **Strategy:**
* **Multi-GPU Backend:** I will migrate from the `qpp` (CPU) backend to the `nvidia-mgpu` backend in CUDA-Q. This allows me to distribute the state vector of the 40+ qubit system across multiple GPUs (e.g., A100s or H100s) to handle the exponential memory requirement.
* **Trotter Step Optimization:** I will benchmark the fidelity vs. depth trade-off. I aim to find the minimum number of Trotter steps required to maintain a sufficient "overlap" with the ground state, minimizing the total kernel execution time on the GPU.



### Classical Acceleration (MTS)

* **Strategy:**
* **Batch Evaluation:** The current CPU implementation evaluates neighbor energies sequentially. I will use **CuPy** to vectorize this process. By broadcasting the `calculate_energy` function, I can evaluate all  neighbors of a sequence simultaneously on the GPU in a single kernel launch.
* **Parallel Populations:** Instead of evolving one population on one core, I will run multiple independent MTS populations in parallel on the GPU, synchronizing them only for "migration" (sharing best solutions) every  generations.



### Hardware Targets

* **Dev Environment:** Qbraid (Standard CPU) for logic validation and unit testing.
* **Production Environment:** Brev.dev (NVIDIA A100-80GB or L4 instances) for performance benchmarking and large  simulations.

---

## 4. The Verification Plan

**Owner:** Quality Assurance PIC

### Unit Testing Strategy

* **Framework:** `pytest`
* **AI Hallucination Guardrails:**
* **Analytical Checks:** Every kernel generated by AI agents must pass a "small " check. I run the kernel, compute the state vector, and compare the expectation value against a brute-force matrix multiplication of the Hamiltonian.
* **Determinism:** I ensure that setting a fixed random seed in the classical MTS produces identical results across runs, ensuring our optimizations don't introduce race conditions.



### Core Correctness Checks

* **Check 1 (Symmetry Invariance):**
* The LABS energy function is invariant under bit-flip and reversal. Our test suite asserts `energy(S) == energy(-S) == energy(reversed(S))` for randomly generated sequences.


* **Check 2 (Ground Truth Validation):**
* For small N's, I run the MTS and compare if the energy outputed is the same as the one that would've been if calculated by hand


---

## 5. Execution Strategy & Success Metrics

**Owner:** Technical Marketing PIC

### Agentic Workflow

* **Plan:**
* **Role-Based Prompting:** I use specific system prompts for our AI coding assistants. One session is the "Quantum Physicist" (deriving math to code), another is the "CUDA Optimization Expert" (refactoring loops for CuPy).
* **Verification Loop:** Code is never blindly accepted. The workflow is: *Agent Generates Code*  *Human Reviews Logic*  *Integration*.



### Success Metrics

* **Metric 1 (Performance):** Achieve a Time-to-Solution (TTS) for  that is at least **5x faster** on the Brev GPU instance compared to the qBraid CPU baseline.
* **Metric 2 (Quality):** The Quantum-Seeded MTS should find the ground state (or best known state) in **fewer generations** (lower iteration count) than the Random-Seeded MTS for .
* **Metric 3 (Scale):** Successfully execute a simulation for , a size intractable for naive verification, demonstrating memory management capabilities.

### Visualization Plan

* **Plot 1:** **"The Quantum Head Start"** - A line plot showing *Current Best Energy* vs. *Generation Count* for both Quantum-Seeded and Random-Seeded runs. I expect the Quantum line to start lower and converge faster.
* **Plot 2:** **"Scaling Wall"** - A log-log plot of *Time per Iteration* vs. *N* comparing the CPU (NumPy) MTS implementation against the GPU (CuPy) implementation.

---

## 6. Resource Management Plan

**Owner:** GPU Acceleration PIC

* **Plan:**
* **Zero-Waste Policy:** Heavy compute (MTS benchmarks) will only be run on Brev instances *after* the logic is verified on the free Qbraid CPU tier.
* **Instance Management:** The Brev instance will be stopped immediately after data collection.
* **Credit Budget:** I allocate 20% of credits for setup/environment debugging, 60% for the main benchmark runs, and hold 20% in reserve for final runs.